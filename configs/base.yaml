# Base configuration for OmniVerifier-TTS evaluation
model:
  omniverifier:
    model_path: "comin/OmniVerifier-7B"
    device: "cuda"
    torch_dtype: "bfloat16"
    max_new_tokens: 2048
    use_vllm: false
    # Set true + provide local path for faster inference
    # use_vllm: true
    # model_path: "models/omniverifier-7b"

  eval_vlm:
    model_path: "Qwen/Qwen2.5-VL-7B-Instruct"
    device: "cuda"
    torch_dtype: "bfloat16"

pipeline:
  max_rounds: 9          # 9 refinement rounds = 10 total steps (matching official max_steps=10)
  early_stop: true       # Stop if OmniVerifier says "yes" (aligned)
  save_intermediates: true

generation:
  backend: "qwen_image"  # "qwen_image" or "gpt_image"
  dashscope_model: "wanx-v1"
  openai_model: "gpt-image-1"
  image_size: 1024
  num_images: 1

evaluation:
  batch_size: 4
  num_workers: 4

output:
  base_dir: "results"
  save_images: true
  save_json: true
